{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# AgentCore Observability\n",
    "\n",
    "In this tutorial we will showcase CloudWatch GenAI Observability Dashboard. We will run a few tests and then review the traces generated by our agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Amazon Bedrock AgentCore Observability helps you trace, debug, and monitor agent performance in production environments.\n",
    "\n",
    "AgentCore Observability provides:\n",
    "\n",
    "* Detailed visualizations of each step in the agent workflow\n",
    "* Real-time visibility into operational performance through CloudWatch dashboards\n",
    "* Telemetry for key metrics such as session count, latency, duration, token usage, and error rates\n",
    "* Rich metadata tagging and filtering for issue investigation\n",
    "* Standardized OpenTelemetry (OTEL)-compatible format for easy integration with existing monitoring stacks\n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/00-Observability.png\" width=\"75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Observability Concepts in AgentCore\n",
    "This section defines the concepts of sessions, traces and spans as they relate to monitoring and observability of agents.\n",
    "        \n",
    "##### Sessions\n",
    "A session represents a complete **interaction context** between user and agent. Sessions encapsulate the entire conversation or interaction flow, maintaining state and context across multiple exchanges. Each session has a unique identifier and captures the full lifecycle of user engagement with the agent, from initialization to termination.\n",
    "##### Traces\n",
    "A trace represents a detailed record of a single request-response cycle beginning from with an agent invocation and may include additional calls to other agents. Traces capture the **complete execution path** of a request, including all internal processing steps, external service calls, decision points, and resource utilization. \n",
    "##### Spans\n",
    "A span represents a discrete, measurable **unit of work** within an agent's execution flow. Spans capture fine-grained operations that occur during request processing, providing detailed visibility into the internal components and steps that make up a complete trace. Each span has a defined start and end time, creating a precise timeline of agent activities and their durations.\n",
    "\n",
    "\n",
    "The relationship between these three observability components can be visualized as:\n",
    "- Sessions (highest level) - Represent complete user conversations or interaction contexts\n",
    "- Traces (middle level) - Represent individual request-response cycles within a session\n",
    "- Spans (lowest level) - Represent specific operations or steps within a trace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Step 1: Examining how OpenTelemetry is configured with AgentCore\n",
    "\n",
    "To enable tracing of AI applications, we need to add the AWS Distro for Open Telemetry (ADOT) SDK  `aws-opentelemetry-distro` to your agent code. When using the `bedrock_agentcore_starter_toolkit` to configure your agent, it takes care of the opentelemetry instrumentation for you.\n",
    "\n",
    "More details are available [here](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/observability-configure.html#observability-configure-custom).\n",
    "\n",
    "1. Open the Code server. Look for the deploy_agentcore/Dockerfile that was created as part of the deployment process in the previous lab.\n",
    "\n",
    "2. Observe that it installs OpenTelemetry for you with RUN pip install aws-opentelemetry-distro>=0.10.1 and then runs it as part of the deployment process CMD [\"opentelemetry-instrument\", \"python\", \"-m\", \"xxx\"]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Step 2: Enable CloudWatch Transaction Search (One-Time Setup)\n",
    "\n",
    "**Note:** You can skip this step if lab 3.2 was executed. You will not see the \"Enable\" button if Transaction Search is already enabled.\n",
    "\n",
    "This is a one-time setup to turn on Amazon CloudWatch Transaction Search. Follow the steps below to enable:\n",
    "\n",
    "1. Open the [CloudWatch Console](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1)\n",
    "2. Navigate to **Application Signals (APM)** → **Transaction search**\n",
    "3. Choose **Enable Transaction Search**\n",
    "4. Select checkbox to **ingest spans as structured logs**\n",
    "5. (Optional) Adjust **X-Ray trace indexing** percentage (default: 1%)\n",
    "6. Choose **Save**\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/observability-ts.png\" width=\"75%\"/>\n",
    "    <img src=\"images/observability-ts-save.png\" width=\"75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Step 3: Run a few invocations\n",
    "\n",
    "When using ADOT, in order to propagate session id correctly, define the X-Amzn-Bedrock-AgentCore-Runtime-Session-Id in the request header. ADOT then sets the session_id correctly in the downstream headers.\n",
    "\n",
    "To propagate a trace ID, invoke the AgentCore runtime with the parameter traceId=<traceId> set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "We can invoke the agent using either the AWS CLI or boto3 (AWS Python SDK).\n",
    "\n",
    "The AWS CLI has both Control Plane (e.g., Create/Update/List/Describe Agents/Memory Strategies) and Runtime (e.g., Invoke Agent/Read Memory/Stop Agent) commands.\n",
    "\n",
    "Let's explore both approaches as we generate telemetry data for observability.\n",
    "\n",
    "#### Invoke Your Agent Using AWS CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available runtimes to verify your agent is deployed and get its ARN\n",
    "!aws bedrock-agentcore-control list-agent-runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "**Invoking AgentCore Runtime with AWS CLI**\n",
    "\n",
    "After listing the available runtimes, you can invoke your agent directly using the AWS CLI. This is useful for testing, automation, or integration with other systems.\n",
    "\n",
    "First, create a payload file with your request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile payload.json\n",
    "{\"query\": \"What products have the best reviews?\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Now invoke the agent runtime and view the response:\n",
    "\n",
    "**Key parameters:**\n",
    "- `--agent-runtime-arn`: The ARN of your deployed agent (obtained from previous steps)\n",
    "- `--payload`: Input data as a file or blob (JSON format for most agents)\n",
    "- `--content-type`: MIME type of the payload (typically \"application/json\")\n",
    "  `--cli-binary-format raw-in-base64-out: Explicitly set the output format \\\n",
    "- `response.json`: Output file where the response will be saved\n",
    "\n",
    "**Optional parameters for advanced use:**\n",
    "- `--runtime-session-id`: Maintain conversation context across multiple invocations\n",
    "- `--runtime-user-id`: Track invocations by specific users\n",
    "- `--qualifier`: Target a specific version or endpoint of the agent\n",
    "\n",
    "For more details, see the [AWS CLI invoke-agent-runtime documentation](https://docs.aws.amazon.com/cli/latest/reference/bedrock-agentcore/invoke-agent-runtime.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the agent runtime (replace <YOUR_AGENT_ARN> with your actual agent ARN)\n",
    "# The --cli-binary-format allows us to use the json directly.  Without this, you need to base64 encode the payload\n",
    "!aws bedrock-agentcore invoke-agent-runtime \\\n",
    "  --agent-runtime-arn \"<YOUR_AGENT_ARN>\" \\\n",
    "  --payload file://payload.json \\\n",
    "  --content-type \"application/json\" \\\n",
    "  --cli-binary-format raw-in-base64-out \\\n",
    "  response.json\n",
    "\n",
    "# View the response\n",
    "!jq . response.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the agent runtime (replace <YOUR_AGENT_ARN> with your actual agent ARN)\n",
    "!aws bedrock-agentcore invoke-agent-runtime \\\n",
    "  --agent-runtime-arn \"<YOUR_AGENT_ARN>\" \\\n",
    "  --payload '{\"query\": \"How many products do we have?\" }' \\\n",
    "  --content-type \"application/json\" \\\n",
    "  --cli-binary-format raw-in-base64-out \\\n",
    "  response.json\n",
    "\n",
    "# View the response\n",
    "!jq . response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Invoke Your Agent Using boto3\n",
    "\n",
    "Let's import the main libraries that we need, and initialize some common variables used further down - `account_id`, `region` and `agentcore_runtime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random, string\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "print(f\"current region: {region}\")\n",
    "account_id = boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "print(f\"current account: {account_id}\")\n",
    "\n",
    "agentcore_runtime = Runtime()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The next cell will automatically retrieve the agent ARN from the previous labs or the AgentCore Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the agent ARN from stored variable or AgentCore Runtime\n",
    "%store -r agent_arn\n",
    "\n",
    "if 'agent_arn' not in locals():\n",
    "    try:\n",
    "        status_response = agentcore_runtime.status()\n",
    "        agent_arn = status_response['endpoint']['agentRuntimeArn']\n",
    "        print(f\"Retrieved agent ARN: {agent_arn}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please run Lab 3.1 or 3.2 first to deploy the agent.\")\n",
    "        agent_arn = \"<REPLACE_WITH_YOUR_AGENT_ARN>\"\n",
    "else:\n",
    "    print(f\"Using stored agent ARN: {agent_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Define a helper function to invoke the agent with proper session tracking for observability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question, user_id=\"user1\", session_id=None):\n",
    "    if session_id is None:\n",
    "        session_id = f\"session_{user_id}\"\n",
    "    \n",
    "    payload = json.dumps({\"prompt\": question, \"user_id\": user_id})\n",
    "    \n",
    "    response = agentcore_client.invoke_agent_runtime(\n",
    "        agentRuntimeArn=agent_arn,\n",
    "        qualifier=\"DEFAULT\",\n",
    "        payload=payload,\n",
    "        runtimeSessionId=session_id\n",
    "    )\n",
    "    \n",
    "    # Read and parse response\n",
    "    body = response['response'].read().decode('utf-8')\n",
    "    data = json.loads(body)\n",
    "    \n",
    "    # Extract and print the text content (which will render \\n as newlines)\n",
    "    text = data['result']['content'][0]['text']\n",
    "    \n",
    "    print(f\"Q: {question}\\n\")\n",
    "    print(text)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Initialize the boto3 client and set up session tracking to ensure all invocations are grouped together in CloudWatch for easier analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import boto3\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "# Set a user id and session id for our test\n",
    "user_id = \"user1\"\n",
    "session_id = f\"test_observability_session_for_{user_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Now invoke the agent to generate telemetry data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask(\n",
    "    \"How many customers reviewed product_890, are those reviews positive or negative?\",\n",
    "    user_id=user_id,\n",
    "    session_id=session_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Step 4: GenAI Observability for visualization\n",
    "\n",
    "The [CloudWatch GenAI Observability](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/GenAI-observability.html) provides Bedrock AgentCore dashboard with Agent, Sessions View & Traces Views to understand the performance and execution flow of Runtime-hosted agents. You can access them by selecting GenAI Observability (Preview) in the CloudWatch console.\n",
    "\n",
    "CloudWatch GenAI Observability provides two pre-built dashboards:\n",
    "- Model Invocations – Detailed metrics on model usage, token consumption, and costs\n",
    "- Amazon Bedrock AgentCore agents – Performance and decision metrics for the Amazon Bedrock agents\n",
    "\n",
    "Click [here](https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#/gen-ai-observability/agent-core?start=-3600000) to navigate to the Bedrock AgentCore dashboard. You can analyze various Agents and their associated interactions under Agent view, Sessions view, and Traces view.\n",
    "\n",
    "Click on **Sessions view** and you will be able to see the session ID that we just tested with above.\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/02-Sessions-view.jpg\" width=\"50%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Understanding the Three Dashboard Views\n",
    "\n",
    "The CloudWatch GenAI Observability dashboard provides three complementary views:\n",
    "\n",
    "**1. Agent View (High-Level Metrics)**\n",
    "- Overall agent performance across all sessions\n",
    "- Invocation counts and success rates\n",
    "- Error rates and latency percentiles\n",
    "- Useful for: Monitoring overall agent health\n",
    "\n",
    "**2. Sessions View (Conversation-Level)**\n",
    "- Individual conversation threads\n",
    "- Session duration and message counts\n",
    "- User interaction patterns\n",
    "- Useful for: Understanding user engagement and conversation flows\n",
    "\n",
    "**3. Traces View (Execution-Level)**\n",
    "- Detailed execution paths for each invocation\n",
    "- LLM calls with token usage\n",
    "- Tool invocations and timing\n",
    "- Knowledge base retrievals\n",
    "- Useful for: Debugging issues and optimizing performance\n",
    "\n",
    "**Trace Trajectory:**\n",
    "When you select a trace, the \"Trajectory\" view shows the complete execution flow:\n",
    "- Which tools were called and in what order\n",
    "- How long each operation took\n",
    "- What data was passed between components\n",
    "- Where errors occurred (if any)\n",
    "\n",
    "This visibility is essential for understanding agent behavior and troubleshooting issues in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Select session \"test_observability_session_700001\" to see a list of traces for this session. In our test there is only trace.\n",
    "\n",
    "The trace provides end-to-end visibility into agent execution paths including LLM calls and tool usage. Select \"Trajectory\" to review the interconnected relationship of the spans and subsequent calls from these spans. For illustration, the screenshot below highlights execution of one of the tools available to the agent and its execution time.\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/03-trace-view.jpg\" width=\"70%\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### View Logs in CloudWatch\n",
    "\n",
    "1. Open the [CloudWatch console](https://us-east-1.console.aws.amazon.com/cloudwatch/)\n",
    "2. In the left navigation pane, expand **Logs** and select **Log groups**\n",
    "3. Search for your agent's log group:\n",
    "   - Standard logs (stdout/stderr): `/aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/[runtime-logs] <UUID>`\n",
    "   - OTEL structured logs: `/aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/runtime-logs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### CloudWatch Logs Structure\n",
    "\n",
    "AgentCore automatically creates two types of log groups for your agent:\n",
    "\n",
    "**Standard Runtime Logs:**\n",
    "- Path: `/aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/[runtime-logs]`\n",
    "- Contains: Application logs, print statements, error messages\n",
    "- Use for: General debugging and application-level troubleshooting\n",
    "\n",
    "**OpenTelemetry Structured Logs:**\n",
    "- Path: `/aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/runtime-logs`\n",
    "- Contains: Detailed telemetry data, spans, traces\n",
    "- Use for: Performance analysis and detailed execution tracing\n",
    "\n",
    "Both log groups are automatically created when you deploy your agent. No additional configuration needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### View Metrics\n",
    "\n",
    "1. Open the [CloudWatch console](https://us-east-1.console.aws.amazon.com/cloudwatch/)\n",
    "2. Select **Metrics** from the left navigation\n",
    "3. Browse to the `bedrock-agentcore` namespace\n",
    "4. Explore the available metrics\n",
    "\n",
    "See [here](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/observability-service-provided.html) for more details on available metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Available CloudWatch Metrics\n",
    "\n",
    "AgentCore publishes metrics to the `bedrock-agentcore` namespace:\n",
    "\n",
    "**Invocation Metrics:**\n",
    "- `Invocations`: Total number of agent invocations\n",
    "- `Errors`: Number of failed invocations\n",
    "- `Duration`: Execution time per invocation\n",
    "\n",
    "**Resource Metrics:**\n",
    "- `CPUUtilization`: Container CPU usage\n",
    "- `MemoryUtilization`: Container memory usage\n",
    "\n",
    "**Custom Metrics:**\n",
    "You can also publish custom metrics from your agent code using CloudWatch PutMetricData API.\n",
    "\n",
    "**Setting Up Alarms:**\n",
    "Use these metrics to create CloudWatch alarms for:\n",
    "- High error rates\n",
    "- Increased latency\n",
    "- Resource exhaustion\n",
    "- Unusual invocation patterns\n",
    "\n",
    "This enables proactive monitoring and alerting for your production agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this tutorial, we demonstrated how to enable CloudWatch GenAI Observability for AgentCore and how to view traces and sessions for a test agent. We also reviewed the available metrics and logs for further analysis and monitoring of the agent's performance. This enables us to gain insights into the agent's performance, identify potential issues, and improve its overall operational efficiency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Congratulations! You've completed all workshop labs and now have a production-ready intelligent RAG agent with:\n",
    "- Unstructured and structured knowledge bases\n",
    "- AgentCore Runtime deployment with automatic scaling\n",
    "- Memory capabilities for conversation context\n",
    "- Full observability through CloudWatch\n",
    "\n",
    "**Cleanup:**\n",
    "- **Workshop-supplied environment:** Simply close your browser tabs - resources will be cleaned up automatically\n",
    "- **Your own AWS account:** Follow the [cleanup instructions](../Cleanup-Instructions.ipynb) to delete resources and avoid ongoing charges\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
